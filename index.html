<html>

<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EWB73JXBN5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EWB73JXBN5');
</script>
	
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Homepage of Gary">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Yang Gao's Homepage</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Yang Gao (高扬)&nbsp;</h1></div>
        <h3>Deep Learning Research Engineer</h3>  
        <p>
            Pre-training Team, InternLM Group <br>
            Shanghai AI Laboratory (SH-AI Lab) <br>
            Shanghai, China, 200232. <br>
	    
            WeChat: garythevoid <br>
            Work Email:  <a href="mailto:gaoyang@pjlab.org.cn">gaoyang@pjlab.org.cn</a> <br>
            Personal Email: <a href="mailto:gaoy2140@gmail.com">gaoy2140@gmail.com</a> <br>
		
            <a href="https://github.com/gaoyang07">[Github]</a>
            <a href="https://scholar.google.com/citations?user=D1pRedQAAAAJ&hl">[Google Scholar]</a>
	        <a href="https://x.com/YangGao07">[Twitter/X]</a> 
            <a href="https://www.zhihu.com/people/garyang">[知乎]</a> 

        </p>
        <!-- <p><a href="./files/YangGao_Resume.pdf">[Resume PDF]</a></p> -->
    </td>

    <td><img src="./files/gary.png" border="0" width="120"></td>
</tr></tbody></table>


<h2>About</h2>
    <p>I am currently a Research Engineer at the pre-training team of InternLM (<a href="https://internlm.org/">书生-浦语</a>) in Shanghai AI Laboratory. Previously, I received Master (2022) and Bachelor (2019) degrees in School of Computer Science and Technology from Northwestern Polytechnial University (NWPU)</a>, advised by <a href="https://teacher.nwpu.edu.cn/m/en/2017010053.html">Prof. Peng Wang</a>.</p>
    
    <p> Currently, My research interests focus on:
    <ul>
    
	    <li>
	        Pre-training for Large Language Models
	    </li>
	    <li>
	        Large-Scale Training Systems
	    </li>
        <li>
	        Advanced Neural Architectures
	    </li>
	  
     </ul>


<h2>Experiences</h2>
	<strong>Academia</strong>
	<ul>
	<li>[2019.09 - 2022.04] <img style="width: 1em;"src="./files/nwpu.jpeg"> M.S. at Northwestern Polytechnical University (Postgraduate recommendation)</li>
	<li>[2015.09 - 2019.06] <img style="width: 1em;"src="./files/nwpu.jpeg"> B.S. at Northwestern Polytechnical University</li>
</ul>
	
 	<strong>Industry</strong>
	<ul>
    <li>[2021.05 - 2022.03] <img style="width: 2.4em;"src="./files/sensetime.jpeg"> SenseTime Research, Engineer Intern on Automated Machine Learning</li>
	<li>[2020.12 - 2021.05] <img style="width: 2.4em;"src="./files/baidu.png"> Baidu Research, Research Intern on Light-weight Object Detection</li>

</ul>


<h2>Selected Publications</h2>

(* denotes equal contributions)<br>

<ul><li><p>InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output<br />
    Pan Zhang, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Rui Qian, Lin Chen, Qipeng Guo, Haodong Duan, Bin Wang, Linke Ouyang, Songyang Zhang, Wenwei Zhang, Yining Li, <strong>Yang Gao</strong>, Peng Sun, Xinyue Zhang, Wei Li, Jingwen Li, Wenhai Wang, Hang Yan, Conghui He, Xingcheng Zhang, Kai Chen, Jifeng Dai, Yu Qiao, Dahua Lin, Jiaqi Wang<br />
    <a href='https://arxiv.org/abs/2407.03320'>[paper]</a >
	<a href='https://github.com/InternLM/InternLM-XComposer'>[code]</a >
    <a href='https://huggingface.co/internlm/internlm-xcomposer2d5-7b'>[huggingface]</a><br>
</li>
</ul>

	
<ul><li><p>Lins: Reducing Communication Overhead of ZeRO for Efficient LLM Training<br />
    Qiaoling Chen, Qinghao Hu, Guoteng Wang, Yingtong Xiong, Ting Huang, Xun Chen, <strong>Yang Gao</strong>, Hang Yan, Yonggang Wen, Tianwei Zhang, Peng Sun<br />
    IWQoS 2024.
    <a href='https://ieeexplore.ieee.org/abstract/document/10682856/'>[paper]</a>
</li>
</ul>

<ul><li><p>InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD<br />
    Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, Linke Ouyang, Songyang Zhang, Haodong Duan, Wenwei Zhang, Yining Li, Hang Yan, <strong>Yang Gao</strong>, Zhe Chen, Xinyue Zhang, Wei Li, Jingwen Li, Wenhai Wang, Kai Chen, Conghui He, Xingcheng Zhang, Jifeng Dai, Yu Qiao, Dahua Lin, Jiaqi Wang<br />
    NeurIPS 2024.
    <a href='https://arxiv.org/abs/2404.06512'>[paper]</a>
	<a href='https://github.com/InternLM/InternLM-XComposer'>[code]</a>
	<a href='https://huggingface.co/internlm/internlm-xcomposer2-4khd-7b'>[huggingface]</a><br>
</li>
</ul>
	
<ul><li><p>InternLM2 Technical Report<br />
    Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, Xiaoyi Dong, Haodong Duan, Qi Fan, Zhaoye Fei, <strong>Yang Gao</strong>, Jiaye Ge, Chenya Gu, Yuzhe Gu, Tao Gui, Aijia Guo, Qipeng Guo, Conghui He, Yingfan Hu, Ting Huang, Tao Jiang, Penglong Jiao, Zhenjiang Jin, Zhikai Lei, Jiaxing Li, Jingwen Li, Linyang Li, Shuaibin Li, Wei Li, Yining Li, Hongwei Liu, Jiangning Liu, Jiawei Hong, Kaiwen Liu, Kuikun Liu, Xiaoran Liu, Chengqi Lv, Haijun Lv, Kai Lv, Li Ma, Runyuan Ma, Zerun Ma, Wenchang Ning, Linke Ouyang, Jiantao Qiu, Yuan Qu, Fukai Shang, Yunfan Shao, Demin Song, Zifan Song, Zhihao Sui, Peng Sun, Yu Sun, Huanze Tang, Bin Wang, Guoteng Wang, Jiaqi Wang, Jiayu Wang, Rui Wang, Yudong Wang, Ziyi Wang, Xingjian Wei, Qizhen Weng, Fan Wu, Yingtong Xiong, Chao Xu, Ruiliang Xu, Hang Yan, Yirong Yan, Xiaogui Yang, Haochen Ye, Huaiyuan Ying, Jia Yu, Jing Yu, Yuhang Zang, Chuyu Zhang, Li Zhang, Pan Zhang, Peng Zhang, Ruijie Zhang, Shuo Zhang, Songyang Zhang, Wenjian Zhang, Wenwei Zhang, Xingcheng Zhang, Xinyue Zhang, Hui Zhao, Qian Zhao, Xiaomeng Zhao, Fengzhe Zhou, Zaida Zhou, Jingming Zhuo, Yicheng Zou, Xipeng Qiu, Yu Qiao, Dahua Lin<br />
    <a href='https://arxiv.org/abs/2403.17297'>[paper]</a>
	<a href='https://github.com/InternLM/InternLM'>[code]</a>
	<a href='https://huggingface.co/collections/internlm/internlm2-65b0ce04970888799707893c'>[huggingface]</a><br>
</li>
</ul>
	
<ul><li><p>Internlm: A multilingual language model with progressively enhanced capabilities<br />
    InternLM Team<br />
    <a href='https://github.com/InternLM/InternLM-techreport'>[paper]</a>
    <a href='https://github.com/InternLM/InternLM'>[code]</a>
    <a href='https://huggingface.co/internlm/internlm-7b'>[huggingface]</a><br>
</li>
</ul>
	
<ul><li><p>NAS-FCOS: Fast neural architecture search for object detection<br />
    *Ning Wang, <strong>*Yang Gao</strong>, *Hao Chen, Peng Wang, Zhi Tian, Chunhua Shen, Yanning Zhang<br />
    CVPR 2020.
    <a href='https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_NAS-FCOS_Fast_Neural_Architecture_Search_for_Object_Detection_CVPR_2020_paper.html'>[paper]</a>
    <a href='https://github.com/Lausannen/NAS-FCOS'>[code]</a><br>
</li>
</ul>


<h2>Honors & Awards</h2>
<ul>
    <li>
        <strong>Intern Future Star (Top 5%), SenseTime</strong>, 2021
    </li>
    <li>
        <strong>Outstanding Graduate of Master Students (Top 5%), NWPU</strong>, 2022
    </li>
    <li>
        <strong>Excellent First-class Scholarship for Master Students, NWPU. (Three consecutive years)</strong>, 2020, 2021, 2022
    </li>
    <li>
        <strong>Outstanding Graduate of Bachelor Students (Top 10%), NWPU</strong>, 2019
    </li>
    <li>
        <strong>Excellent First-class Scholarship for Bachelor Students, NWPU</strong>, 2017, 2018
    </li>


</ul>


</html>
